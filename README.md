# ETL Pipeline

## Overview

This project implements a robust ETL (Extract, Transform, Load) pipeline designed to automate data ingestion, cleaning, transformation, and storage. It is suitable for structured datasets and can be customized for a wide range of data sources, including APIs, CSV files, and databases.

## Features

- Extract data from multiple sources (e.g., APIs, CSV, databases)
- Transform data using pandas and custom transformation logic
- Load data into a target destination (e.g., PostgreSQL, SQLite, AWS S3)
- Modular, extensible architecture
- Logging and error handling
- Configurable via environment variables or `.env` file

## Tech Stack

- python 3.x
- pandas
- Sqlite3
- requests
- dotenv

## Architecture
